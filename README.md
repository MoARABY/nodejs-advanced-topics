# LLM integration and embeddings
This part integrates OpenAI API and groq to generate embeddings for your application data.
The goal is to transform text into high-dimensional vectors that can be used for semantic search, recommendations, and AI-powered features.

## ðŸš€ Features
- asking questations to AI from your app
- Generates vector embeddings using OpenAI models.
- Stores embeddings for efficient semantic search instead of simple keyword search.
- Easy to integrate into any Node.js / Express project.

## ðŸ“¦ llm Installation
- Install the OpenAI package : npm i openai
- Install groq sdk : npm i groq-sdk

## project usage
- first start with basic askAI controller
- then working with embedding model to advanced AI-Query
